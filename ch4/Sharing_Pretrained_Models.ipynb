{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kki1MX10K7bo"
      },
      "source": [
        "# Sharing pretrained models (PyTorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Sharing Pretrained Models on the Hugging Face Hub (PyTorch)\n",
        "\n",
        "This notebook demonstrates all the main ways to share your pretrained models and tokenizers using Hugging Face.  \n",
        "You'll learn to push models via API, Python SDK, and with Git‚Äîall best practices for reproducible, shareable ML!"
      ],
      "metadata": {
        "id": "NrIfvdTNLC5m"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvWSG_X4K7bp"
      },
      "source": [
        "## 1Ô∏è‚É£ Install Required Dependencies\n",
        "\n",
        "We start by installing the necessary libraries: `transformers`, `datasets`, and `evaluate` for modeling and metrics, as well as `git-lfs` for handling large files in the Hub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjYIGs5xK7bq"
      },
      "outputs": [],
      "source": [
        "# Install main libraries and git-lfs for model upload support\n",
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "!apt install git-lfs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1suUhPxEK7br"
      },
      "source": [
        "## 2Ô∏è‚É£ Git Configuration\n",
        "\n",
        "Set up your Git identity. This is required for version control and model pushes.  \n",
        "Replace the email and name with your GitHub/Hugging Face credentials.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TR8Fo07vK7br"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"you@example.com\"\n",
        "!git config --global user.name \"Your Name\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbF5OGnAK7bs"
      },
      "source": [
        "## 3Ô∏è‚É£ Authenticate with the Hugging Face Hub\n",
        "\n",
        "Login so that your notebook can create and update model repositories for your account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rskuoq2VK7bs"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "# Login and authenticate this environment to acces your Hugging Face account\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4Ô∏è‚É£ Define TrainingArguments for Push-to-Hub (if you use Trainer)\n",
        "\n",
        "You can instruct Hugging Face‚Äôs Trainer to push all checkpoints and the final model automatically."
      ],
      "metadata": {
        "id": "mBFdVPR1LgR0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hBvEq4RK7bs"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "# Set up training arguments to enable automatic upload to the Hub\n",
        "triainig_args=TrainingArguments(\n",
        "    \"bert-finetuned-mrpc\",\n",
        "     save_strategy=\"epoch\",\n",
        "     push_to_hub=True\n",
        "\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5Ô∏è‚É£ Push Model and Tokenizer Using `.push_to_hub()`\n",
        "\n",
        "Let's load a pretrained model and tokenizer and push them to a new repo on the Hub, all from code!"
      ],
      "metadata": {
        "id": "EnNIK0qyLt-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "\n",
        "checkpoint=\"camembert-base\"\n",
        "\n",
        "# Load pretrained model and tokenizer\n",
        "model=AutoModelForMaskedLM.from_pretrained(checkpoint)\n",
        "tokenizer=AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "# Push model and tokenizer to your namespace on the Hub\n",
        "model.push_to_hub(\"dummy-model\")\n",
        "tokenizer.push_to_hub(\"dummy-model\")"
      ],
      "metadata": {
        "id": "oOQvOWxCLwwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ü§ù Advanced: Uploading to Organizations or with Tokens\n",
        "\n",
        "You can also push to an org or with a specific token:"
      ],
      "metadata": {
        "id": "z3xrj6hfLltZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        #"Push tokenizer to an organization namespace (and/or use a specific auth token)\n",
        "\n",
        "tokenizer.push_to_hub(\"dummy-model\",orgainization=\"huggingface\")\n",
        "tokenizer.push_to_hub(\"dummy-model\",organization=\"huggingface\",use_auth_token=\"<TOKEN>\")"
      ],
      "metadata": {
        "id": "SQQaBcTML4I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 6Ô∏è‚É£ Managing Repositories Programmatically with `huggingface_hub`\n",
        "\n",
        "The `huggingface_hub` package gives you fine control: create/delete repos, upload/delete files, update metadata, and more."
      ],
      "metadata": {
        "id": "IszcGQF5L6_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import(\n",
        "# User management\n",
        "login,\n",
        "logout,\n",
        "whoami,\n",
        "\n",
        "# Repository management\n",
        "create_repo,\n",
        "delete_repo,\n",
        "update_repo_visibility,\n",
        "\n",
        "# Information\n",
        "list_models,\n",
        "list_datasets,\n",
        "#list_metrics,\n",
        "list_repo_files,\n",
        "upload_file,\n",
        "delete_file,\n",
        ")"
      ],
      "metadata": {
        "id": "sL8u0f8kL-vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a new model repository (your account or organization):\n",
        "\n",
        "Use `create_repo()` for a user or org."
      ],
      "metadata": {
        "id": "yeq0EQb5MBy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import create_repo\n",
        "\n",
        "create_repo(\"dummy-model1\")\n",
        "# Or, in an organization\n",
        "create_repo(\"dummy-model1\", organization=\"huggingface\")"
      ],
      "metadata": {
        "id": "3NgymJKNMEmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7Ô∏è‚É£ Full Local Git-like Control with `Repository` Class\n",
        "\n",
        "Use this class to manage your repo with traditional Git (add, commit, push)."
      ],
      "metadata": {
        "id": "Ye5qF2wJMIPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import Repository\n",
        "\n",
        "# Clone your remote to repo to a local folder\n",
        "repo= Repository(\"<path_to_dummy_folder>\",clone_from=\"<namespace/dummy-model\")\n",
        "\n",
        "# Standard git operations\n",
        "repo.git_pull()\n",
        "repo.git_add()\n",
        "repo.git_commit(\"Commit messgae\")\n",
        "repo.git_push()\n",
        "\n",
        "# Save your model/tokenizer to this folder then push\n",
        "model.save_pretrained(\"<path_to_dummy_folder>\")\n",
        "tokenizer.save_pretrained(\"<path_to_dummy_folder>\")\n",
        "repo.git_add()\n",
        "repo.git_commit(\"Add model and tokenizer files\")\n",
        "repo.git_push()\n"
      ],
      "metadata": {
        "id": "06CcNkNwMJZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8Ô∏è‚É£ (Optional) Manual Git/LFS Push\n",
        "\n",
        "For advanced or very large projects, clone the repo with Git and use LFS to manage weights."
      ],
      "metadata": {
        "id": "Et_GFg6dML3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Summary\n",
        "\n",
        "This notebook covers all best practices for sharing models and tokenizers on the Hugging Face Hub using Python and Git workflows.  \n",
        "After uploading, remember to:\n",
        "- Check your repo on [huggingface.co](https://huggingface.co/)  \n",
        "- Edit your model card for clarity and completeness  \n",
        "- Share the link on your portfolio or with collaborators!\n",
        "\n",
        "You‚Äôre now ready to share any model you build, directly from a reproducible ML notebook!"
      ],
      "metadata": {
        "id": "CcriGS-5MO69"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Sharing pretrained models (PyTorch)",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
