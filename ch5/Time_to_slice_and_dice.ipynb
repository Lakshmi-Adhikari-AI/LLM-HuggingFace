{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WKcgMyw71Fl"
      },
      "source": [
        "# Time to slice and dice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qIN4qX871Fp"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKY89vST71Fp"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Time to Slice and Dice\n",
        "\n",
        "Most real-world datasets need cleaning and restructuring before model training. In this notebook, we use the Drug Reviews dataset and demonstrate powerful ü§ó Datasets capabilities for preprocessing, cleaning, and analysis.\n"
      ],
      "metadata": {
        "id": "b2n4bHWw8eSm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£ Download and Load the Drug Review Data\n",
        "\n",
        "We use the patient drug reviews dataset from UCI ML Repo. We'll load the train and test data from downloaded TSV files using the Datasets library.\n"
      ],
      "metadata": {
        "id": "KyZYY4En8vA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and unzip the dataset from UCI\n",
        "!wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\"\n",
        "!unzip drugsCom_raw.zip\n",
        "\n",
        "# Load the data splits;TSV is a tab-seperated variant of CSV\n",
        "from datasets import load_dataset\n",
        "\n",
        "data_files={\"train\":\"drugsComTrain_raw.tsv\",\"test\":\"drugsComTest_raw.tsv\"}\n",
        "# Note: '\\t' is the tab seperator\n",
        "drug_dataset = load_dataset(\"csv\",data_files=data_files,delimiter=\"\\t\")\n"
      ],
      "metadata": {
        "id": "GEaQnyaG8yqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2Ô∏è‚É£ Sampling a Small Subset\n",
        "\n",
        "Let's take a random subset of 1,000 examples for fast exploration and preview the data.\n"
      ],
      "metadata": {
        "id": "hEO5gk7F9_KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle training data and select 1000 random samples\n",
        "drug_sample=drug_dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "\n",
        "print(drug_sample)\n",
        "\n",
        "# peek at the first three examples\n",
        "drug_sample[:3]"
      ],
      "metadata": {
        "id": "TqfQkxSu-Hm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3Ô∏è‚É£ Does the Unnamed: 0 Column Uniquely Identify Patients?\n",
        "\n",
        "Let's check if this column (likely a patient ID) is unique using the `.unique()` method.\n"
      ],
      "metadata": {
        "id": "5CmCI9pr_LCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique IDs test: should match number of rows if unique\n",
        "for split in drug_dataset.keys():\n",
        "  assert len(drug_dataset[split])==len(drug_dataset[split].unique(\"Unnamed:0\"))"
      ],
      "metadata": {
        "id": "56H27Cq6_bQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4Ô∏è‚É£ Rename Columns for Clarity\n",
        "\n",
        "Make the dataset more readable by renaming `Unnamed: 0` to `patient_id` everywhere.\n"
      ],
      "metadata": {
        "id": "O7sN8TbcAg91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename patient ID column in both splits\n",
        "drug_dataset=drug_dataset.rename_column(\"Unnamed:0\",\"patient_id\")\n"
      ],
      "metadata": {
        "id": "nl3RwcptArMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5Ô∏è‚É£ Normalize the 'Condition' Column\n",
        "\n",
        "Convert all `condition` entries to lowercase for consistency.\n"
      ],
      "metadata": {
        "id": "m3qO2tayBJn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lowercase_condition(example):\n",
        "  # Lowercase only non-empty conditions\n",
        "  return {\"condition\":example[\"condition\"].lower()}\n",
        "\n",
        "# But first,drop rows where condtition is  None (can't lowecase None)\n",
        "drug_dataset=drug_dataset.filter(lambda x: x[\"condition\"] is not None)\n",
        "\n",
        "# Now safely lowercase everything\n",
        "drug_dataset=drug_dataset.map(lowercase_condition)\n",
        "# Preview first three normalized conditions\n",
        "drug_dataset[\"train\"][\"condition\"][:3]\n"
      ],
      "metadata": {
        "id": "PdKLejz7BYbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6Ô∏è‚É£ Add a New Column: Review Length\n",
        "\n",
        "Count the number of words in each review for further filtering.\n"
      ],
      "metadata": {
        "id": "auabztKZC2NV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_review_length(example):\n",
        "  # Split the review text by whitespace and count words\n",
        "  return {\"review_length\":len(example[\"review\"].split())}\n",
        "\n",
        "# Add the column\n",
        "drug_dataset = drug_dataset.map(compute_review_length)\n",
        "drug_dataset[\"train\"][0]"
      ],
      "metadata": {
        "id": "2lOQ7zM-C6Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7Ô∏è‚É£ Filter Very Short Reviews\n",
        "\n",
        "Keep only reviews with more than 30 words for more informative training data.\n"
      ],
      "metadata": {
        "id": "FQ5J9aWqD-Qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drug_dataset=drug_dataset.filter(lambda x: x[\"review_length\"]>30)\n",
        "print(drug_dataset.num_rows) # Number of rows in each split after filtering"
      ],
      "metadata": {
        "id": "tsbt3UoUEE9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8Ô∏è‚É£ Remove HTML Character Codes\n",
        "\n",
        "Use the `html` library to clean up review text for model readability.\n"
      ],
      "metadata": {
        "id": "Ad4pHeJHE2E3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import html\n",
        "\n",
        "# Unescape all HTML entities in the review column\n",
        "drug_dataset=drug_dataset.map(lambda x:{\"review\":html.unescape(x[\"review\"])})"
      ],
      "metadata": {
        "id": "Mo5NVRokE5u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9Ô∏è‚É£ Bonus: Accelerated Preprocessing with Batched Map\n",
        "\n",
        "The `.map()` method can batch-process for much faster execution (especially for tokenization).\n"
      ],
      "metadata": {
        "id": "1lWzGQpFFuUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_drug_dataset=drug_dataset.map(\n",
        "    lambda x: {\"review\":[html.unescape(o) for o in x[\"review\"]]},batched=True\n",
        ")"
      ],
      "metadata": {
        "id": "igzXLN86FzId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîü Power User: Use Pandas Interoperability\n",
        "\n",
        "Convert to and from pandas for advanced grouping, plotting, or statistics.\n"
      ],
      "metadata": {
        "id": "VYenKQxjGhpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the train split to a DataFrame\n",
        "drug_dataset.set_format(\"pandas\")\n",
        "train_df=drug_dataset[\"train\"][:]\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "pMXXDnXAGnet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£1Ô∏è‚É£ Creating a Validation Set\n",
        "\n",
        "Split the training set into train and validation splits (80/20), then add back the original test set.\n"
      ],
      "metadata": {
        "id": "YzYQKkpKHGzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split training set for validation, keeping shuffle reproducible\n",
        "drug_dataset_clean = drug_dataset[\"train\"].train_test_split(train_size=0.8,seed=42)\n",
        "# Rename test -> validation for clarity\n",
        "drug_dataset_clean[\"validation\"]=drug_dataset_clean.pop(\"test\")\n",
        "# Add the original test split\n",
        "drug_dataset_clean[\"test\"]=drug_dataset[\"test\"]\n",
        "print(drug_dataset_clean)"
      ],
      "metadata": {
        "id": "bMImzvXuHS5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£2Ô∏è‚É£ Save Your Cleaned Dataset\n",
        "\n",
        "Save as Arrow (for speed/robustness) and as JSON lines (for sharing or inspection).\n"
      ],
      "metadata": {
        "id": "TesCn1P_IcIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dataset to disk in fast Arrow format\n",
        "drug_dataset_clean.save_to_disk(\"drug-reviews\")\n",
        "# Save each split to JSONL\n",
        "for split,ds in drug_dataset_clean.items():\n",
        "  ds.to_json(f\"drug-reviews-{split}.jsonl\")"
      ],
      "metadata": {
        "id": "ffKDBDQMIl-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£3Ô∏è‚É£ Load a Dataset from Disk\n",
        "\n",
        "Instantly reload your saved Arrow dataset for future use.\n"
      ],
      "metadata": {
        "id": "EXsz0XleJJUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_from_disk\n",
        "drug_dataset_reloaded=load_from_disk(\"drug-reviews\")\n",
        "print(drug_dataset_reloaded)"
      ],
      "metadata": {
        "id": "BSEiTc0aJari"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Time to slice and dice",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}