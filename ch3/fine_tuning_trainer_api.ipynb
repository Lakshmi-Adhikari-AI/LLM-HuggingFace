{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lakshmi-Adhikari-AI/LLM-HuggingFace/blob/main/ch3/mod3_fine_tuning_trainer_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TCAaRrRwAMo"
      },
      "source": [
        "# Fine-tuning a model with the Trainer API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsfvqZ2XwAMp"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSp1jwifwAMp"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üóÇÔ∏è Data Preparation for Fine-Tuning a Model with Trainer API\n",
        "\n",
        "**In this section, we:**\n",
        "\n",
        "- üì• **Load the MRPC dataset** (sentence pairs with labels for paraphrase detection)\n",
        "- üî§ **Load the BERT tokenizer** to convert text into input IDs\n",
        "- ‚úÇÔ∏è **Tokenize the dataset** ‚Äì prepare sentence pairs for the model\n",
        "- üõí **Set up a data collator** for dynamic padding during batching"
      ],
      "metadata": {
        "id": "_itroF1nwC9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from datasets import load_dataset                       # For loading datasets\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding  # For tokenization and padding\n",
        "\n",
        "# Load the GLUE MRPC dataset, which contains pairs of sentences and labels indicating if they are paraphrases\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "\n",
        "# Specify the pretrained model checkpoint for BERT (uncased version)\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "\n",
        "# Load the tokenizer corresponding to the pretrained BERT model\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "# Define a function to tokenize pairs of sentences in the dataset, truncating sequences longer than model allows\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
        "\n",
        "# Apply the tokenizer function to the entire dataset with batching for speed and efficiency\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "\n",
        "# Initialize a data collator that dynamically pads inputs in each batch to the longest sequence in that batch\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "id": "OHuxnCtSwOwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèãÔ∏è Training & Fine-Tuning with the Trainer API\n",
        "\n",
        "**In this section, we:**\n",
        "- ‚öôÔ∏è **Define training arguments** (where to save models, how often to evaluate, number of epochs, more)\n",
        "- üß† **Load our classification model** (BERT with a sequence classification head)\n",
        "- ü§ñ **Set up the Trainer** to handle all the training loop and evaluation logic\n",
        "- üöÄ **Start fine-tuning** the model on our preprocessed dataset\n"
      ],
      "metadata": {
        "id": "H3QPx9dDwTBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Required Libraries\n",
        "from transformers import TrainingArguments,Trainer,AutoModelForSequenceClassification\n",
        "\n",
        "# Step 1: Define training arguments\n",
        "training_args = TrainingArguments(\"test-trainer\")\n",
        "\n",
        "# Step 2: Load model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint,num_labels=2)\n",
        "\n",
        "# Step 3: Set up Trainer\n",
        "trainer=Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    processing_class=tokenizer,\n",
        ")\n",
        "\n",
        "# Step 4: Fine-tune modek on our dataset 'MRPC'\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "bBG7xFNAwV6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Evaluation During Fine-Tuning\n",
        "\n",
        "**In this section, we:**\n",
        "- üîç Use the `Trainer.predict()` method to get model predictions on the validation set.\n",
        "- üéØ Define a `compute_metrics()` function that converts raw model outputs (logits) into class predictions and calculates evaluation metrics like accuracy and F1 score.\n",
        "- üìà Incorporate `compute_metrics()` with the `Trainer` to report validation performance automatically during training.\n"
      ],
      "metadata": {
        "id": "ordRJ_lhwZ4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import Required Libraries\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from transformers import TrainingArguments,Trainer,AutoModelForSequenceClassification\n",
        "\n",
        "# Step 1: Define the compute_metrics function\n",
        "def compute_metrics(eval_preds):\n",
        "  # Load the standard evaluation metric for MRPC ( from the GLUE benchmark)\n",
        "  metric = evaluate.load(\"glue\",\"mrpc\")\n",
        "\n",
        "  # Unpack the predictions and labels from eval_preds tuple\n",
        "  logits,labels=eval_preds\n",
        "\n",
        "  # Convert logits to predicted class indices by taking the argmax of each prediction's scores\n",
        "  predictions = np.argmax(logits,axis=-1)\n",
        "\n",
        "  # Compute and return the evaluation metrics (accuracy and f1)\n",
        "  return metric.compute(predictions=predictions,references=labels)\n",
        "\n",
        "# Step 2: Setup TrainingArguments with evaluation enabled at the of each epoch\n",
        "training_args = TrainingArguments(\"test-trainer\",eval_strategy=\"epoch\")\n",
        "\n",
        "# Step 3: Load model (new instance for fresh training with metrics)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint,num_labels=2)\n",
        "\n",
        "# Step 4: Initialize the Trainer with compute_metrics function\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer, # use tokenizer instead of processing_class for latest version\n",
        "    compute_metrics=compute_metrics # pass our metric function\n",
        ")\n",
        "\n",
        "# Step 5: Train the model; metrics will be reported each epoch\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "-DQQ4NR8wdFO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Fine-tuning a model with the Trainer API or Keras",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
